
encodings:
    xxx_encodings is a transformers.tokenization_utils_base.BatchEncoding object
        treat like a dict: keys = ["input_ids", "attention_masks"]
    
        treat like a list:
            one item of it is a tokenizers.Encoding
            ids:[101, ..., ..., 1012, 0, 0, 0, ...]
            type_ids: [0, 0, 0 ...] probably used to distinguish between the first and second sentences
            tokens: ['[CLS]', 'china', '...', '.', '[SEP]', '[PAD]', ...]

labels:
    a list of [0, 0, 1, 1, ...]